{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42769dd8",
   "metadata": {},
   "source": [
    "For one frame we have F0=1/T0  (Hz)\n",
    "\n",
    "We compute the mean of F0 of all frames and their standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "324339b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: AH_064F_7AB034C9-72E4-438B-A9B3-AD7FDA1596C5.wav\n",
      "Processing: AH_114S_A89F3548-0B61-4770-B800-2E26AB3908B6.wav\n",
      "Processing: AH_121A_BD5BA248-E807-4CB9-8B53-47E7FFE5F8E2.wav\n",
      "Processing: AH_123G_559F0706-2238-447C-BA39-DB5933BA619D.wav\n",
      "Processing: AH_195B_39DA6A45-F4CC-492A-80D4-FB79049ACC22.wav\n",
      "Processing: AH_197T_7552379A-2310-46E1-9466-9D8045C990B8.wav\n",
      "Processing: AH_222K_FC9D2763-1836-460B-954F-37F23D6CD81D.wav\n",
      "Processing: AH_264Z_593C20CD-0A54-4177-B031-26EE147080A3.wav\n",
      "Processing: AH_292J_201CB911-31C1-4CD0-BD73-4FBA4A16C21F.wav\n",
      "Processing: AH_322A_C3BF5535-A11E-498E-94EB-BE7E74099FFB.wav\n",
      "Processing: AH_325A_3EB21DC7-C340-4D0E-AC9E-0EABF217BBEE.wav\n",
      "Processing: AH_325J_7F5F27AA-5A93-43CF-AB17-FC53940BF4B0.wav\n",
      "Processing: AH_333L_6C551A6E-CC47-410E-AA49-2DC0A86E6489.wav\n",
      "Processing: AH_378G_3C2A05CE-36E4-4956-8FC2-0494B27D3EA8.wav\n",
      "Processing: AH_420J_07C96C2C-6E96-4A2F-BEC9-5CB71DB309B6.wav\n",
      "Processing: AH_444B_E1586F09-1BF5-408D-A55E-96D9E8B76A43.wav\n",
      "Processing: AH_456K_CBF60DD0-82AA-430E-A5E9-E1D3AE175CCB.wav\n",
      "Processing: AH_469Z_5BB05B2C-39C4-434D-9445-244E7580F840.wav\n",
      "Processing: AH_473R_E4947FD3-23C1-44F1-BCE4-DC59D8269FDE.wav\n",
      "Processing: AH_501F_4BDDBB93-EA99-4B1C-AD7F-4D874F39FB0C.wav\n",
      "Processing: AH_511K_DDC6D065-56B3-436B-9D08-73326C791B69.wav\n",
      "Processing: AH_523T_66147C3C-938A-4CF9-913E-5D49D72BD8B6.wav\n",
      "Processing: AH_528T_6A746E6E-FB60-4363-842F-A7368A1E5B2C.wav\n",
      "Processing: AH_538M_AE709CB7-1123-47F8-8BD2-000158BDBC01.wav\n",
      "Processing: AH_562E_151814F5-BB0F-44EF-9A22-FE2862FC3411.wav\n",
      "Processing: AH_569E_B26CCA1E-29AD-48DD-9947-48DB8A56CA31.wav\n",
      "Processing: AH_596S_BBE9779F-C440-42D3-9C96-4CD6121D1F7E.wav\n",
      "Processing: AH_619B_5CF9C4CA-31AA-4F22-8E57-8E53618CC224.wav\n",
      "Processing: AH_621N_204CF3E2-1DA0-4908-A47F-78997B1BAFC2.wav\n",
      "Processing: AH_667J_605FB4D5-E0DB-4B9B-8F58-784561C51693.wav\n",
      "Processing: AH_678A_2E7AFA48-34C1-4DAD-A73C-95F7ABF6B138.wav\n",
      "Processing: AH_743R_66BD23F9-D685-4315-86F8-7697B5084F7B.wav\n",
      "Processing: AH_753G_073DCC32-4397-4719-A019-DDD41F30F5F1.wav\n",
      "Processing: AH_777G_4C8ACC89-7FE2-4174-AE3A-B21B39A0C869.wav\n",
      "Processing: AH_777R_A36CF7FA-37FD-483E-98FE-040942B1DF49.wav\n",
      "Processing: AH_789Y_20CB672C-5F66-425E-8707-BE5B7FF807E2.wav\n",
      "Processing: AH_803T_66094C40-AE64-4AD3-AA97-B052C69DA3EF.wav\n",
      "Processing: AH_821C_8F9D5EF0-18B2-4967-B36D-82E014792BC3.wav\n",
      "Processing: AH_888A_7F1444B0-B12C-4B55-AF2A-463395DCAF3C.wav\n",
      "Processing: AH_904H_85B22FC1-BA09-4A17-A374-B00B2445CD27.wav\n",
      "Processing: AH_942A_3F7867F3-1AE2-4BE6-B5EC-AC3157D310CF.wav\n",
      "\n",
      "Done. Saved CSV to: F0_features.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import parselmouth\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# Your paths (as you gave them)\n",
    "# =========================================\n",
    "AUDIO_DIR = Path(r\"C:\\Users\\user\\Downloads\\23849127\\HC_AH\\HC_AH\")\n",
    "OUTPUT_CSV = \"F0_features.csv\"\n",
    "\n",
    "\n",
    "def compute_f0_stats_sustained(file_path,\n",
    "                               time_step=0.01,\n",
    "                               pitch_floor=75,\n",
    "                               pitch_ceiling=300):\n",
    "    \"\"\"\n",
    "    Compute F0_mean_sustained and F0_std_sustained from a sustained /a/ recording.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str or Path\n",
    "        Path to the WAV file (sustained /a/).\n",
    "    time_step : float\n",
    "        Time step between pitch estimates (in seconds).\n",
    "    pitch_floor : float\n",
    "        Minimum expected F0 in Hz (e.g. 75 Hz).\n",
    "    pitch_ceiling : float\n",
    "        Maximum expected F0 in Hz (e.g. 300 Hz).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    f0_mean : float\n",
    "        Mean F0 over voiced frames (Hz).\n",
    "    f0_std : float\n",
    "        Standard deviation of F0 over voiced frames (Hz).\n",
    "    \"\"\"\n",
    "    snd = parselmouth.Sound(str(file_path))\n",
    "\n",
    "    # Praat pitch extraction\n",
    "    pitch = snd.to_pitch(time_step=time_step,\n",
    "                         pitch_floor=pitch_floor,\n",
    "                         pitch_ceiling=pitch_ceiling)\n",
    "\n",
    "    # F0 values (Hz)\n",
    "    f0_values = pitch.selected_array[\"frequency\"]  # shape: (num_frames,)\n",
    "\n",
    "    # Only voiced frames (F0 > 0)\n",
    "    f0_voiced = f0_values[f0_values > 0]\n",
    "\n",
    "    if len(f0_voiced) == 0:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    f0_mean = float(np.mean(f0_voiced))\n",
    "    f0_std = float(np.std(f0_voiced, ddof=0))  # population std\n",
    "\n",
    "    return f0_mean, f0_std\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Collect all .wav files in the given folder (non-recursive)\n",
    "    wav_paths = sorted(AUDIO_DIR.glob(\"*.wav\"))\n",
    "\n",
    "    if not wav_paths:\n",
    "        print(f\"No .wav files found in: {AUDIO_DIR}\")\n",
    "        return\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for wav_path in wav_paths:\n",
    "        filename = wav_path.name\n",
    "        print(f\"Processing: {filename}\")\n",
    "\n",
    "        try:\n",
    "            f0_mean, f0_std = compute_f0_stats_sustained(wav_path)\n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing {filename}: {e}\")\n",
    "            f0_mean, f0_std = np.nan, np.nan\n",
    "\n",
    "        rows.append({\n",
    "            \"filename\": filename,\n",
    "            \"F0_mean_sustained_Hz\": f0_mean,\n",
    "            \"F0_std_sustained_Hz\": f0_std,\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(OUTPUT_CSV, index=False)\n",
    "    print(f\"\\nDone. Saved CSV to: {OUTPUT_CSV}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e463f5af",
   "metadata": {},
   "source": [
    "Intensity\n",
    "\n",
    "Intensity is the sound pressure level in decibels(dB).\n",
    "\n",
    "We compute the intensity for each frame and then take the mean and the standard deviation of the intensity values we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2417f433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: AH_064F_7AB034C9-72E4-438B-A9B3-AD7FDA1596C5.wav\n",
      "Processing: AH_114S_A89F3548-0B61-4770-B800-2E26AB3908B6.wav\n",
      "Processing: AH_121A_BD5BA248-E807-4CB9-8B53-47E7FFE5F8E2.wav\n",
      "Processing: AH_123G_559F0706-2238-447C-BA39-DB5933BA619D.wav\n",
      "Processing: AH_195B_39DA6A45-F4CC-492A-80D4-FB79049ACC22.wav\n",
      "Processing: AH_197T_7552379A-2310-46E1-9466-9D8045C990B8.wav\n",
      "Processing: AH_222K_FC9D2763-1836-460B-954F-37F23D6CD81D.wav\n",
      "Processing: AH_264Z_593C20CD-0A54-4177-B031-26EE147080A3.wav\n",
      "Processing: AH_292J_201CB911-31C1-4CD0-BD73-4FBA4A16C21F.wav\n",
      "Processing: AH_322A_C3BF5535-A11E-498E-94EB-BE7E74099FFB.wav\n",
      "Processing: AH_325A_3EB21DC7-C340-4D0E-AC9E-0EABF217BBEE.wav\n",
      "Processing: AH_325J_7F5F27AA-5A93-43CF-AB17-FC53940BF4B0.wav\n",
      "Processing: AH_333L_6C551A6E-CC47-410E-AA49-2DC0A86E6489.wav\n",
      "Processing: AH_378G_3C2A05CE-36E4-4956-8FC2-0494B27D3EA8.wav\n",
      "Processing: AH_420J_07C96C2C-6E96-4A2F-BEC9-5CB71DB309B6.wav\n",
      "Processing: AH_444B_E1586F09-1BF5-408D-A55E-96D9E8B76A43.wav\n",
      "Processing: AH_456K_CBF60DD0-82AA-430E-A5E9-E1D3AE175CCB.wav\n",
      "Processing: AH_469Z_5BB05B2C-39C4-434D-9445-244E7580F840.wav\n",
      "Processing: AH_473R_E4947FD3-23C1-44F1-BCE4-DC59D8269FDE.wav\n",
      "Processing: AH_501F_4BDDBB93-EA99-4B1C-AD7F-4D874F39FB0C.wav\n",
      "Processing: AH_511K_DDC6D065-56B3-436B-9D08-73326C791B69.wav\n",
      "Processing: AH_523T_66147C3C-938A-4CF9-913E-5D49D72BD8B6.wav\n",
      "Processing: AH_528T_6A746E6E-FB60-4363-842F-A7368A1E5B2C.wav\n",
      "Processing: AH_538M_AE709CB7-1123-47F8-8BD2-000158BDBC01.wav\n",
      "Processing: AH_562E_151814F5-BB0F-44EF-9A22-FE2862FC3411.wav\n",
      "Processing: AH_569E_B26CCA1E-29AD-48DD-9947-48DB8A56CA31.wav\n",
      "Processing: AH_596S_BBE9779F-C440-42D3-9C96-4CD6121D1F7E.wav\n",
      "Processing: AH_619B_5CF9C4CA-31AA-4F22-8E57-8E53618CC224.wav\n",
      "Processing: AH_621N_204CF3E2-1DA0-4908-A47F-78997B1BAFC2.wav\n",
      "Processing: AH_667J_605FB4D5-E0DB-4B9B-8F58-784561C51693.wav\n",
      "Processing: AH_678A_2E7AFA48-34C1-4DAD-A73C-95F7ABF6B138.wav\n",
      "Processing: AH_743R_66BD23F9-D685-4315-86F8-7697B5084F7B.wav\n",
      "Processing: AH_753G_073DCC32-4397-4719-A019-DDD41F30F5F1.wav\n",
      "Processing: AH_777G_4C8ACC89-7FE2-4174-AE3A-B21B39A0C869.wav\n",
      "Processing: AH_777R_A36CF7FA-37FD-483E-98FE-040942B1DF49.wav\n",
      "Processing: AH_789Y_20CB672C-5F66-425E-8707-BE5B7FF807E2.wav\n",
      "Processing: AH_803T_66094C40-AE64-4AD3-AA97-B052C69DA3EF.wav\n",
      "Processing: AH_821C_8F9D5EF0-18B2-4967-B36D-82E014792BC3.wav\n",
      "Processing: AH_888A_7F1444B0-B12C-4B55-AF2A-463395DCAF3C.wav\n",
      "Processing: AH_904H_85B22FC1-BA09-4A17-A374-B00B2445CD27.wav\n",
      "Processing: AH_942A_3F7867F3-1AE2-4BE6-B5EC-AC3157D310CF.wav\n",
      "\n",
      "Done. Saved CSV to: Intensity_features.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import parselmouth\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# Your paths (given by you)\n",
    "# =========================================\n",
    "AUDIO_DIR = Path(r\"C:\\Users\\user\\Downloads\\23849127\\HC_AH\\HC_AH\")\n",
    "OUTPUT_CSV = \"Intensity_features.csv\"\n",
    "\n",
    "\n",
    "def compute_intensity_stats_sustained(file_path,\n",
    "                                      time_step=0.01,\n",
    "                                      minimum_pitch=75):\n",
    "    \"\"\"\n",
    "    Compute Intensity_mean_sustained and Intensity_std_sustained\n",
    "    from a sustained /a/ recording.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str or Path\n",
    "        Path to the WAV file (sustained /a/).\n",
    "    time_step : float\n",
    "        Time step between intensity estimates (in seconds).\n",
    "    minimum_pitch : float\n",
    "        Minimum pitch in Hz used by Praat to set the analysis window.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    intensity_mean : float\n",
    "        Mean intensity over frames (dB).\n",
    "    intensity_std : float\n",
    "        Standard deviation of intensity over frames (dB).\n",
    "    \"\"\"\n",
    "    snd = parselmouth.Sound(str(file_path))\n",
    "\n",
    "    # Praat intensity extraction (in dB)\n",
    "    intensity = snd.to_intensity(time_step=time_step,\n",
    "                                 minimum_pitch=minimum_pitch)\n",
    "\n",
    "    # Intensity values is usually shape (1, num_frames)\n",
    "    intensity_values = intensity.values.T.flatten()  # -> (num_frames,)\n",
    "\n",
    "    # Keep only finite values\n",
    "    valid = np.isfinite(intensity_values)\n",
    "    intensity_valid = intensity_values[valid]\n",
    "\n",
    "    if len(intensity_valid) == 0:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    intensity_mean = float(np.mean(intensity_valid))\n",
    "    intensity_std = float(np.std(intensity_valid, ddof=0))\n",
    "\n",
    "    return intensity_mean, intensity_std\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Collect all .wav files in the given folder (non-recursive)\n",
    "    wav_paths = sorted(AUDIO_DIR.glob(\"*.wav\"))\n",
    "\n",
    "    if not wav_paths:\n",
    "        print(f\"No .wav files found in: {AUDIO_DIR}\")\n",
    "        return\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for wav_path in wav_paths:\n",
    "        filename = wav_path.name\n",
    "        print(f\"Processing: {filename}\")\n",
    "\n",
    "        try:\n",
    "            intensity_mean, intensity_std = compute_intensity_stats_sustained(wav_path)\n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing {filename}: {e}\")\n",
    "            intensity_mean, intensity_std = np.nan, np.nan\n",
    "\n",
    "        rows.append({\n",
    "            \"filename\": filename,\n",
    "            \"Intensity_mean_sustained_dB\": intensity_mean,\n",
    "            \"Intensity_std_sustained_dB\": intensity_std,\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(OUTPUT_CSV, index=False)\n",
    "    print(f\"\\nDone. Saved CSV to: {OUTPUT_CSV}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b0f584",
   "metadata": {},
   "source": [
    "RPDE:\n",
    "\n",
    "Recurrence Period Density Entropy over the sustained /a/.\n",
    "It measures how irregular and unpredictable the vibration pattern is.\n",
    "Closer to 0 → more regular; closer to 1 → more complex / irregular.\n",
    "\n",
    "DFA_alpha:\n",
    "\n",
    "Scaling exponent (α) from Detrended Fluctuation Analysis on the signal.\n",
    "It measures long-range correlations in the waveform (fractal-like behavior).\n",
    "Different α values reflect different “texture” of the voice dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73350288",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import parselmouth\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# Your paths\n",
    "# =========================================\n",
    "AUDIO_DIR = Path(r\"C:\\Users\\user\\Downloads\\23849127\\HC_AH\\HC_AH\")\n",
    "OUTPUT_CSV = \"RPDE/DFA_features.csv\"\n",
    "\n",
    "\n",
    "def compute_rpde(signal, sr, m=3, tau_sec=0.01, r=0.3, max_T=200):\n",
    "    \"\"\"\n",
    "    Compute a simple version of Recurrence Period Density Entropy (RPDE).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    signal : 1D np.ndarray\n",
    "        Audio samples (mono).\n",
    "    sr : float\n",
    "        Sampling rate (Hz).\n",
    "    m : int\n",
    "        Embedding dimension.\n",
    "    tau_sec : float\n",
    "        Embedding delay in seconds.\n",
    "    r : float\n",
    "        Recurrence radius in (normalized) state space.\n",
    "    max_T : int\n",
    "        Maximum recurrence period (in frames) to consider.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rpde : float\n",
    "        Normalized entropy in [0, 1] (higher => more irregular),\n",
    "        or NaN if it cannot be computed.\n",
    "    \"\"\"\n",
    "    x = np.array(signal, dtype=float)\n",
    "\n",
    "    if x.size < 2:\n",
    "        return np.nan\n",
    "\n",
    "    # Normalize\n",
    "    x = x - np.mean(x)\n",
    "    std = np.std(x)\n",
    "    if std == 0:\n",
    "        return np.nan\n",
    "    x = x / std\n",
    "\n",
    "    tau = max(1, int(tau_sec * sr))\n",
    "    N = x.size - (m - 1) * tau\n",
    "    if N <= 1:\n",
    "        return np.nan\n",
    "\n",
    "    # Time-delay embedding\n",
    "    emb = np.empty((N, m), dtype=float)\n",
    "    for i in range(N):\n",
    "        emb[i] = x[i:i + m * tau:tau]\n",
    "\n",
    "    counts = np.zeros(max_T, dtype=float)\n",
    "\n",
    "    # For each point, look for first recurrence within radius r\n",
    "    for i in range(N - 1):\n",
    "        # Distances to future points\n",
    "        diffs = emb[i + 1:] - emb[i]\n",
    "        dists = np.linalg.norm(diffs, axis=1)\n",
    "\n",
    "        rec_idx = np.where(dists < r)[0]\n",
    "        if rec_idx.size == 0:\n",
    "            continue\n",
    "\n",
    "        # First recurrence time (in \"frames\" of the embedded series)\n",
    "        T = rec_idx[0] + 1\n",
    "        if 1 <= T < max_T:\n",
    "            counts[T] += 1\n",
    "\n",
    "    total = counts.sum()\n",
    "    if total == 0:\n",
    "        return np.nan\n",
    "\n",
    "    p = counts / total\n",
    "    p = p[p > 0]\n",
    "\n",
    "    if p.size == 0:\n",
    "        return np.nan\n",
    "\n",
    "    H = -np.sum(p * np.log(p))\n",
    "    H_norm = H / np.log(p.size)  # normalized to [0,1]\n",
    "\n",
    "    return float(H_norm)\n",
    "\n",
    "\n",
    "def compute_dfa_alpha(signal, min_window=10, max_window=None, num_windows=20):\n",
    "    \"\"\"\n",
    "    Compute DFA scaling exponent alpha for a 1D signal.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    signal : 1D np.ndarray\n",
    "        Audio samples (mono).\n",
    "    min_window : int\n",
    "        Minimum window size (samples).\n",
    "    max_window : int or None\n",
    "        Maximum window size (samples). If None, use N//4.\n",
    "    num_windows : int\n",
    "        Number of window sizes (log-spaced).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    alpha : float\n",
    "        DFA scaling exponent, or NaN if it cannot be computed.\n",
    "    \"\"\"\n",
    "    x = np.array(signal, dtype=float)\n",
    "    N = x.size\n",
    "    if N < 2:\n",
    "        return np.nan\n",
    "\n",
    "    x = x - np.mean(x)\n",
    "    y = np.cumsum(x)\n",
    "\n",
    "    if max_window is None:\n",
    "        max_window = N // 4\n",
    "    if max_window <= min_window:\n",
    "        return np.nan\n",
    "\n",
    "    # Log-spaced window sizes\n",
    "    window_sizes = np.unique(\n",
    "        np.floor(\n",
    "            np.logspace(np.log10(min_window), np.log10(max_window), num_windows)\n",
    "        ).astype(int)\n",
    "    )\n",
    "\n",
    "    F = []\n",
    "    valid_sizes = []\n",
    "\n",
    "    for s in window_sizes:\n",
    "        if s < 2:\n",
    "            continue\n",
    "        n_segments = N // s\n",
    "        if n_segments < 2:\n",
    "            continue\n",
    "\n",
    "        # Reshape into segments\n",
    "        y_seg = y[:n_segments * s].reshape(n_segments, s)\n",
    "        t = np.arange(s)\n",
    "        rms_list = []\n",
    "\n",
    "        for seg in y_seg:\n",
    "            coeffs = np.polyfit(t, seg, 1)\n",
    "            trend = np.polyval(coeffs, t)\n",
    "            detrended = seg - trend\n",
    "            rms = np.sqrt(np.mean(detrended ** 2))\n",
    "            rms_list.append(rms)\n",
    "\n",
    "        F_s = np.mean(rms_list)\n",
    "        if F_s > 0:\n",
    "            F.append(F_s)\n",
    "            valid_sizes.append(s)\n",
    "\n",
    "    if len(F) < 2:\n",
    "        return np.nan\n",
    "\n",
    "    log_s = np.log(valid_sizes)\n",
    "    log_F = np.log(F)\n",
    "\n",
    "    alpha, _ = np.polyfit(log_s, log_F, 1)\n",
    "    return float(alpha)\n",
    "\n",
    "\n",
    "def compute_nonlinear_features_sustained(file_path):\n",
    "    \"\"\"\n",
    "    Compute RPDE_sustained and DFA_alpha_sustained for a sustained /a/ file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rpde : float\n",
    "    dfa_alpha : float\n",
    "    \"\"\"\n",
    "    snd = parselmouth.Sound(str(file_path))\n",
    "    samples = snd.values[0]  # mono\n",
    "    sr = snd.sampling_frequency\n",
    "\n",
    "    # Downsample to ~4 kHz to reduce cost for RPDE/DFA\n",
    "    target_sr = 4000.0\n",
    "    factor = max(1, int(sr // target_sr))\n",
    "    samples_ds = samples[::factor]\n",
    "    sr_ds = sr / factor\n",
    "\n",
    "    if samples_ds.size < 100:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    rpde = compute_rpde(samples_ds, sr_ds)\n",
    "    dfa_alpha = compute_dfa_alpha(samples_ds)\n",
    "\n",
    "    return rpde, dfa_alpha\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Collect all .wav files in the given folder (non-recursive)\n",
    "    wav_paths = sorted(AUDIO_DIR.glob(\"*.wav\"))\n",
    "\n",
    "    if not wav_paths:\n",
    "        print(f\"No .wav files found in: {AUDIO_DIR}\")\n",
    "        return\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for wav_path in wav_paths:\n",
    "        filename = wav_path.name\n",
    "        print(f\"Processing: {filename}\")\n",
    "\n",
    "        try:\n",
    "            rpde, dfa_alpha = compute_nonlinear_features_sustained(wav_path)\n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing {filename}: {e}\")\n",
    "            rpde, dfa_alpha = np.nan, np.nan\n",
    "\n",
    "        rows.append({\n",
    "            \"filename\": filename,\n",
    "            \"RPDE_sustained\": rpde,\n",
    "            \"DFA_alpha_sustained\": dfa_alpha,\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(OUTPUT_CSV, index=False)\n",
    "    print(f\"\\nDone. Saved CSV to: {OUTPUT_CSV}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aeaac1a",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Reading text recordings dataset required.\n",
    "\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14f429c",
   "metadata": {},
   "source": [
    "We will compute F0 now but for the reading a text recordings dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca31b9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb9adb38",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pdproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
